# Model Files (Not Included in Git)

## ğŸ“ Missing Files (Too Large for GitHub)

The following files are excluded from git due to size limits:

### Trained Models (280MB+):
- `rnn_sentiment_model.pt` (20MB)
- `rnn_checkpoints/best_model.pt` (19MB)
- `transformer/model.safetensors` (255MB)
- `transformer/checkpoint-*/` (1GB+)

### Training Data (500MB+):
- `model_training/data/raw/Twitter.csv` (228MB)
- `model_training/data/raw/IMDB Dataset.csv` (63MB)
- `model_training/data/raw/Amazon_Health_and_Personal_Care.jsonl` (216MB)

## ğŸ”„ How to Get These Files

### Option 1: Train Models Yourself (Recommended)
```bash
# Navigate to project
cd "CST-435 JT/DNN"

# Activate virtual environment
source venv/bin/activate

# Download training data (instructions in model_training/data/raw/README.md)

# Train RNN model
cd model_training/model_b
python train.py

# Train DistilBERT model
cd ../model_c
python train_transformer.py
```

### Option 2: Download Pre-trained Models
**For Graders/Reviewers**: Contact the repository owner for access to pre-trained models.

The trained models can be shared via:
- Google Drive
- Dropbox
- OneDrive
- Direct file transfer

### Option 3: Use Demo Mode (Vercel Deployment)
The deployed version at Vercel uses lightweight rule-based sentiment analysis.

No model files needed for the demo deployment.

## ğŸ“Š Expected Model Performance

When you train or obtain the models, you should see:

- **RNN Model**: ~87.56% accuracy
- **DistilBERT Model**: ~94.22% accuracy
- **Hybrid Ensemble**: ~92% accuracy

## ğŸ—‚ï¸ File Structure (After Training)

```
outputs/
â”œâ”€â”€ rnn_sentiment_model.pt          # RNN model (20MB)
â”œâ”€â”€ transformer/
â”‚   â”œâ”€â”€ model.safetensors          # DistilBERT (255MB)
â”‚   â”œâ”€â”€ config.json
â”‚   â”œâ”€â”€ tokenizer_config.json
â”‚   â””â”€â”€ vocab.txt
â”œâ”€â”€ rnn_checkpoints/
â”‚   â””â”€â”€ best_model.pt              # Best RNN checkpoint (19MB)
â””â”€â”€ sentiment.db                    # SQLite database (auto-created)
```

## âš ï¸ Important Notes

1. **GitHub Limits**: Files over 100MB cannot be pushed to GitHub
2. **Total Size**: All models combined = ~2GB
3. **Git LFS**: Not used to keep repository simple
4. **Submission**: Models excluded from git, documented in README

## ğŸ“ For Course Submission

**Instructor**: These model files are too large for GitHub submission.

**Alternatives**:
1. âœ… Live demo on Vercel (no models needed)
2. âœ… Source code in GitHub (training scripts included)
3. âœ… Local demo during office hours/presentation
4. âœ… Video recording of full system
5. âœ… Share models via cloud storage if requested

## ğŸ“ Training Time Estimates

- RNN training: ~30 minutes (CPU) / ~10 minutes (GPU)
- DistilBERT fine-tuning: ~2 hours (CPU) / ~30 minutes (GPU)
- Total training time: ~2-3 hours (CPU) / ~40 minutes (GPU)

## ğŸ’¾ Storage Requirements

- Training data: 500MB
- Trained models: 280MB
- Checkpoints: 1GB (can delete after training)
- Virtual environment: 1GB
- **Total**: ~2.7GB

## ğŸ”— Related Documentation

- Training guide: `model_training/README.md`
- Deployment guide: `VERCEL_DEPLOYMENT.md`
- Main README: `../README.md`

---

**Note**: This is a standard practice for ML projects. Model files are distributed separately from source code due to size constraints.
